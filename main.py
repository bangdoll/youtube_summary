import os
import sys
import json
import asyncio
import logging
import secrets
import pydantic
from typing import List
from PIL import Image
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI, Request, Response, UploadFile, File, Form, BackgroundTasks
from fastapi.responses import HTMLResponse, StreamingResponse, RedirectResponse, JSONResponse, FileResponse
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from starlette.middleware.sessions import SessionMiddleware
from authlib.integrations.starlette_client import OAuth
from uvicorn.middleware.proxy_headers import ProxyHeadersMiddleware

# Import our core engine
import youtube_summary
import slide_generator

# Import Cost Tracker
try:
    from cost_tracker import tracker as cost_tracker
except ImportError:
    # Handle case where it might be run from a different context
    sys.path.append(os.path.dirname(os.path.abspath(__file__)))
    from cost_tracker import tracker as cost_tracker

app = FastAPI(title="Youtube Summary AI")

# Trust Proxy Headers (CRITICAL for Cloud Run/Render behind Load Balancer)
# This ensures request.url is seen as HTTPS, preventing redirect_uri mismatches and session cookie issues
app.add_middleware(ProxyHeadersMiddleware, trusted_hosts=["*"])

# Session middleware for OAuth
# Use a stable key if env var not set, to prevent session invalidation on restart
# In production, users SHOULD set SECRET_KEY env var
DEFAULT_SECRET_KEY = "stable_secret_key_for_youtube_summary_app_fix_restart_auth_issue"
SECRET_KEY = os.getenv("SECRET_KEY", DEFAULT_SECRET_KEY) 
app.add_middleware(
    SessionMiddleware, 
    secret_key=SECRET_KEY, 
    max_age=1209600, # 14 Days (14 * 24 * 60 * 60)
    https_only=True, # Secure only
    same_site="lax"
)

# OAuth setup
oauth = OAuth()
GOOGLE_CLIENT_ID = os.getenv("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET", "")
ALLOWED_EMAILS = os.getenv("ALLOWED_EMAILS", "").split(",")

if GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET:
    oauth.register(
        name="google",
        client_id=GOOGLE_CLIENT_ID,
        client_secret=GOOGLE_CLIENT_SECRET,
        server_metadata_url="https://accounts.google.com/.well-known/openid-configuration",
        client_kwargs={"scope": "openid email profile"},
    )

# Ensure web directory exists
WEB_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "web")
os.makedirs(WEB_DIR, exist_ok=True)
TEMP_DIR = os.path.join(WEB_DIR, "temp")
os.makedirs(TEMP_DIR, exist_ok=True)

# Mount static files
app.mount("/static", StaticFiles(directory=WEB_DIR), name="static")

# Lock for single-threaded execution
processing_lock = asyncio.Lock()


def is_auth_enabled():
    """Check if Google OAuth is configured."""
    return bool(GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET)


def get_user_email(request: Request):
    """Get the logged-in user's email from session."""
    return request.session.get("user_email")


def is_allowed_user(email: str):
    """Check if the email is in the allowed list."""
    if not ALLOWED_EMAILS or ALLOWED_EMAILS == [""]:
        return True  # No restriction if no emails configured
    return email in ALLOWED_EMAILS


@app.get("/")
async def read_root(request: Request):
    index_path = os.path.join(WEB_DIR, "index.html")
    if os.path.exists(index_path):
        with open(index_path, "r", encoding="utf-8") as f:
            return HTMLResponse(content=f.read())
    return HTMLResponse(content="<h1>Web Interface Loading...</h1>")


@app.get("/api/check-auth")
async def check_auth(request: Request):
    """Check authentication status."""
    if not is_auth_enabled():
        return {"auth_required": False, "logged_in": True}
    
    user_email = get_user_email(request)
    if user_email and is_allowed_user(user_email):
        return {"auth_required": True, "logged_in": True, "email": user_email}
    
    return {"auth_required": True, "logged_in": False}


@app.get("/auth/login")
async def login(request: Request):
    """Redirect to Google OAuth login."""
    if not is_auth_enabled():
        return RedirectResponse(url="/")
    
    # Determine redirect URI
    redirect_uri = str(request.url_for("auth_callback"))
    
    # Force HTTPS in production (non-localhost)
    # This fixes the 'redirect_uri_mismatch' 400 error on Cloud Run/Render
    if "localhost" not in redirect_uri and "127.0.0.1" not in redirect_uri:
        redirect_uri = redirect_uri.replace("http://", "https://")
    
    print(f"[Auth] Redirect URI sent to Google: {redirect_uri}") # Debug log
    
    return await oauth.google.authorize_redirect(request, redirect_uri)


@app.get("/auth/callback")
async def auth_callback(request: Request):
    """Handle Google OAuth callback."""
    if not is_auth_enabled():
        return RedirectResponse(url="/")
    
    try:
        token = await oauth.google.authorize_access_token(request)
        user_info = token.get("userinfo")
        
        if not user_info:
            return HTMLResponse("<h1>âŒ ç„¡æ³•å–å¾—ä½¿ç”¨è€…è³‡è¨Š</h1>", status_code=400)
        
        email = user_info.get("email", "")
        
        if not is_allowed_user(email):
            return HTMLResponse(f"<h1>âŒ æœªæˆæ¬Š</h1><p>{email} ä¸åœ¨å…è¨±çš„ä½¿ç”¨è€…æ¸…å–®ä¸­ã€‚</p>", status_code=403)
        
        # Store user info in session
        request.session["user_email"] = email
        request.session["user_name"] = user_info.get("name", "")
        request.session["user_picture"] = user_info.get("picture", "")
        
        return RedirectResponse(url="/")
    
    except Exception as e:
        return HTMLResponse(f"<h1>âŒ ç™»å…¥å¤±æ•—</h1><p>{str(e)}</p>", status_code=400)


@app.get("/auth/logout")
async def logout(request: Request):
    """Clear session and log out."""
    request.session.clear()
    return RedirectResponse(url="/")


@app.get("/api/user")
async def get_user(request: Request):
    """Get current user info."""
    if not is_auth_enabled():
        return {"email": "local", "name": "Local User", "picture": ""}
    
    return {
        "email": request.session.get("user_email", ""),
        "name": request.session.get("user_name", ""),
        "picture": request.session.get("user_picture", ""),
    }


@app.get("/api/summarize")
async def summarize(request: Request, url: str, gemini_key: str = None, openai_key: str = None):
    """SSE Endpoint that streams processing logs and final result."""
    # Check authentication
    # Logic:
    # 1. If User provides Key -> Allow (BYOK Mode)
    # 2. If User Logged In & Authorized -> Allow (Server Key Mode)
    # 3. Else -> Deny
    
    is_authorized = False
    
    # Check for BYOK
    if gemini_key or openai_key:
        is_authorized = True
    
    # Check for Login (if not already authorized via BYOK)
    if not is_authorized and is_auth_enabled():
        user_email = get_user_email(request)
        if user_email and is_allowed_user(user_email):
            is_authorized = True
            
    if not is_authorized:
        async def error_gen():
            yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ è«‹å…ˆç™»å…¥æˆ–åœ¨è¨­å®šä¸­å¡«å…¥æ‚¨çš„ API Key'})}\\n\\n"
        return StreamingResponse(error_gen(), media_type="text/event-stream")
    
    return StreamingResponse(event_generator(url, gemini_key, openai_key), media_type="text/event-stream")



async def event_generator(url: str, gemini_key: str = None, openai_key: str = None):
    yield f"data: {json.dumps({'type': 'log', 'data': 'ğŸ”Œ é€£ç·šå»ºç«‹ä¸­...'})}\n\n"
    
    if processing_lock.locked():
        yield f"data: {json.dumps({'type': 'error', 'message': 'âš ï¸ ç³»çµ±æ­£å¿™æ–¼è™•ç†å¦ä¸€å€‹å½±ç‰‡ï¼Œè«‹ç¨å€™ã€‚'})}\n\n"
        return

    async with processing_lock:
        queue = asyncio.Queue()
        yield f"data: {json.dumps({'type': 'log', 'data': 'ğŸš€ ç³»çµ±æ ¸å¿ƒå·²å•Ÿå‹•'})}\n\n"
        
        # Log Auth Status for debugging
        auth_status = "âœ… å·²å•Ÿç”¨ (Google OAuth)" if is_auth_enabled() else "âš ï¸ æœªå•Ÿç”¨ (ä½¿ç”¨ Local æ¨¡å¼)"
        yield f"data: {json.dumps({'type': 'log', 'data': f'ğŸ”’ å®‰å…¨æ¨¡çµ„: {auth_status}'})}\n\n"
        if is_auth_enabled():
             yield f"data: {json.dumps({'type': 'log', 'data': f'ğŸ‘¤ å…è¨±æ¸…å–®: {len(ALLOWED_EMAILS)} ä½ä½¿ç”¨è€…'})}\n\n"

        loop = asyncio.get_running_loop()
        
        # Check cost limit warning
        try:
            current_cost = cost_tracker.get_total_cost()
            if cost_tracker.is_limit_exceeded(limit=20.0):
                yield f"data: {json.dumps({'type': 'log', 'data': f'âš ï¸ æ³¨æ„ï¼šæœ¬æœˆ API ä½¿ç”¨é‡é ä¼°å·²é” ${current_cost:.2f} USD (è¶…é $20 é™é¡)'})}\n\n"
            else:
                 yield f"data: {json.dumps({'type': 'log', 'data': f'ğŸ“Š æœ¬æœˆ API ç´¯è¨ˆä½¿ç”¨é‡: ${current_cost:.4f} USD'})}\n\n"
        except Exception as e:
            logging.error(f"Cost tracker check failed: {e}")
            yield f"data: {json.dumps({'type': 'log', 'data': f'âš ï¸ ç„¡æ³•å–å¾—æˆæœ¬è³‡è¨Š: {str(e)}'})}\n\n"

        def log_callback(msg, *args, **kwargs):
            formatted_msg = str(msg)
            loop.call_soon_threadsafe(queue.put_nowait, formatted_msg)

        youtube_summary.set_log_callback(log_callback)
        
        executor = ThreadPoolExecutor(max_workers=1)
        future = loop.run_in_executor(executor, run_processing_safe, url, gemini_key, openai_key)
        
        start_time = asyncio.get_running_loop().time()
        
        while True:
            try:
                while not queue.empty():
                    msg = queue.get_nowait()
                    yield f"data: {json.dumps({'type': 'log', 'data': msg})}\n\n"
                
                # Check for completion
                if future.done():
                    try:
                        filename, content = future.result()
                        clean_filename = os.path.basename(filename)
                        yield f"data: {json.dumps({'type': 'result', 'data': content, 'filename': clean_filename})}\n\n"
                        yield f"data: {json.dumps({'type': 'done'})}\n\n"
                    except Exception as e:
                        yield f"data: {json.dumps({'type': 'error', 'message': f'âŒ ç™¼ç”ŸéŒ¯èª¤: {str(e)}'})}\n\n"
                    break
                
                # Enforce global timeout (10 mins = 600s)
                if asyncio.get_running_loop().time() - start_time > 600:
                     yield f"data: {json.dumps({'type': 'error', 'message': 'âŒ è™•ç†é€¾æ™‚ (10åˆ†é˜)ï¼Œç³»çµ±å¼·åˆ¶çµ‚æ­¢ã€‚'})}\n\n"
                     # We cannot kill the thread easily, but we break the loop to release the lock (via async with processing_lock exit)
                     break
                
                try:
                    msg = await asyncio.wait_for(queue.get(), timeout=2.0)
                    yield f"data: {json.dumps({'type': 'log', 'data': msg})}\n\n"
                except asyncio.TimeoutError:
                    # Send a ping
                    yield f"data: {json.dumps({'type': 'ping'})}\n\n"
                    continue
                    
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': f'ç³»çµ±éŒ¯èª¤: {str(e)}'})}\n\n"
                break
        
        youtube_summary.set_log_callback(print)


def run_processing_safe(url, gemini_key=None, openai_key=None):
    """Wrapper to run the pipeline."""
    return youtube_summary.process_video_pipeline(url, gemini_key=gemini_key, openai_key=openai_key)

@app.post("/api/preview-pdf")
async def preview_pdf(file: UploadFile = File(...)):
    """
    æ¥æ”¶ PDFï¼Œå›å‚³æ‰€æœ‰é é¢çš„é è¦½åœ–ç‰‡ URLã€‚
    """
    if not file.filename.lower().endswith(".pdf"):
        return JSONResponse(status_code=400, content={"error": "è«‹ä¸Šå‚³ PDF æª”æ¡ˆ"})

    try:
        pdf_bytes = await file.read()
        
        # ä½¿ç”¨ç·šç¨‹æ± åŸ·è¡Œè½‰æª”ï¼Œé¿å…é˜»å¡ Event Loop
        loop = asyncio.get_running_loop()
        image_urls = await loop.run_in_executor(
            None, 
            slide_generator.generate_preview_images, 
            pdf_bytes, 
            TEMP_DIR
        )
        
        return JSONResponse({
            "total_pages": len(image_urls),
            "images": image_urls
        })
        
    except Exception as e:
        print(f"Preview PDF Error: {e}")
        return JSONResponse(status_code=500, content={"error": f"é è¦½ç”Ÿæˆå¤±æ•—: {str(e)}"})

    except Exception as e:
        print(f"Preview PDF Error: {e}")
        return JSONResponse(status_code=500, content={"error": f"é è¦½ç”Ÿæˆå¤±æ•—: {str(e)}"})


@app.post("/api/analyze-slides")
async def analyze_slides(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    gemini_key: str = Form(...),
    selected_pages: str = Form(None),
    remove_icon: bool = Form(False)
):
    """
    [Web Editor Step 1] æ¥æ”¶ PDFï¼Œé€²è¡Œåˆ†æèˆ‡å»å­—ï¼Œä½†ä¸ç”Ÿæˆ PPTXã€‚
    å›å‚³: Streaming NDJSON
    {"progress": 1, "total": 10}
    {"analyses": [...], "cleaned_images": [...]}
    """
    if not file.filename.lower().endswith(".pdf"):
        return JSONResponse(status_code=400, content={"error": "è«‹ä¸Šå‚³ PDF æª”æ¡ˆ"})

    # Read file content first
    try:
        pdf_bytes = await file.read()
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"è®€å–æª”æ¡ˆå¤±æ•—: {e}"})

    # Queue for streaming events
    queue = asyncio.Queue()

    # Save Uploaded File to Temp
    temp_pdf_filename = f"upload_{secrets.token_hex(8)}.pdf"
    temp_pdf_path = os.path.join(TEMP_DIR, temp_pdf_filename)
    
    try:
        with open(temp_pdf_path, "wb") as f:
            while content := await file.read(1024 * 1024):  # 1MB chunks
                f.write(content)
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": f"å„²å­˜æš«å­˜æª”æ¡ˆå¤±æ•—: {e}"})

    async def run_analysis():
        try:
            # è§£æ selected_pages
            selected_indices = None
            if selected_pages:
                try:
                    selected_indices = json.loads(selected_pages)
                    if not isinstance(selected_indices, list):
                        selected_indices = None
                except:
                    pass
            
            async def report_progress(current, total, message=None):
                data = {"progress": current, "total": total}
                if message:
                    data["message"] = message
                await queue.put(data)

            # Send initial feedback
            await queue.put({"message": "æ­£åœ¨è®€å– PDF çµæ§‹èˆ‡åˆå§‹åŒ–åˆ†æ...", "progress": 0, "total": 0})

            # 1. åŸ·è¡Œæ ¸å¿ƒåˆ†æ
            analyses, cleaned_images = await slide_generator.analyze_presentation(
                temp_pdf_path, gemini_key, file.filename, selected_indices, 
                remove_icon=remove_icon,
                progress_callback=report_progress
            )
            
            # 2. å„²å­˜åœ–ç‰‡
            cleaned_image_urls = []
            loop = asyncio.get_running_loop()
            
            for img in cleaned_images:
                img_filename = f"clean_{secrets.token_hex(8)}.jpg"
                img_path = os.path.join(TEMP_DIR, img_filename)
                # Run sync IO in thread
                await loop.run_in_executor(None, img.save, img_path, "JPEG", 85)
                cleaned_image_urls.append(f"/static/temp/{img_filename}")
            
            # Result
            await queue.put({
                "analyses": analyses,
                "cleaned_images": cleaned_image_urls
            })
            
        except Exception as e:
            await queue.put({"error": str(e)})
        finally:
            await queue.put(None) # Signal end
            # Cleanup PDF
            try:
                if os.path.exists(temp_pdf_path):
                    os.remove(temp_pdf_path)
            except:
                pass
            cleaned_image_urls = []
            loop = asyncio.get_running_loop()
            
            for img in cleaned_images:
                img_filename = f"clean_{secrets.token_hex(8)}.jpg"
                img_path = os.path.join(TEMP_DIR, img_filename)
                # Run sync IO in thread
                await loop.run_in_executor(None, img.save, img_path, "JPEG", 85)
                cleaned_image_urls.append(f"/static/temp/{img_filename}")
            
            # Result
            await queue.put({
                "analyses": analyses,
                "cleaned_images": cleaned_image_urls
            })
            
        except Exception as e:
            await queue.put({"error": str(e)})
        finally:
            await queue.put(None) # Signal end

    # Start background task
    asyncio.create_task(run_analysis())

    async def event_generator():
        while True:
            data = await queue.get()
            if data is None:
                break
            # NDJSON format
            yield json.dumps(data) + "\n"

    return StreamingResponse(event_generator(), media_type="application/x-ndjson")


class GenerateSlidesRequest(pydantic.BaseModel):
    analyses: List[dict]
    cleaned_images: List[str]  # é€™è£¡æ¥æ”¶çš„æ˜¯åœ–ç‰‡ URLPath
    filename: str = "presentation"

@app.post("/api/generate-slides-data")
async def generate_slides_data(
    request: Request,
    data: GenerateSlidesRequest
):
    """
    [Web Editor Step 2] æ¥æ”¶å‰ç«¯ç·¨è¼¯å¾Œçš„ JSON è³‡æ–™èˆ‡åœ–ç‰‡è·¯å¾‘ï¼Œç”Ÿæˆ PPTXã€‚
    """
    try:
        # 1. é‚„åŸåœ–ç‰‡ç‰©ä»¶ (å¾ URL è·¯å¾‘è®€å– temp æª”æ¡ˆ)
        # URL æ ¼å¼: /static/temp/filename.jpg
        # å¯¦é«”è·¯å¾‘: WEB_DIR/temp/filename.jpg
        
        pil_images = []
        for url in data.cleaned_images:
            # å»é™¤ /static/temp/ å‰ç¶´ï¼Œæˆ–æ˜¯ç›´æ¥å–æª”å
            filename = os.path.basename(url)
            file_path = os.path.join(TEMP_DIR, filename)
            
            if os.path.exists(file_path):
                img = Image.open(file_path)
                pil_images.append(img)
            else:
                # è‹¥æ‰¾ä¸åˆ°æš«å­˜æª” (å¯èƒ½éæœŸ)ï¼Œé€™æœƒæ˜¯å€‹å•é¡Œ
                # ç°¡å–®è§£æ³•ï¼šå‰ç«¯éœ€ç¢ºä¿åœ–ç‰‡æ™‚æ•ˆï¼Œæˆ–é‡æ–°ä¸Šå‚³
                # é€™è£¡è£œä¸€å€‹å…¨ç™½åœ–é¿å…å´©æ½°
                pil_images.append(Image.new('RGB', (1024, 768), 'white'))

        # 2. ç”Ÿæˆ PPTX
        output_dir = "temp_slides"
        os.makedirs(output_dir, exist_ok=True)
        
        output_filename = f"{os.path.splitext(data.filename)[0]}_edited.pptx"
        output_path = os.path.join(output_dir, output_filename)
        
        await asyncio.to_thread(
            slide_generator.create_pptx_from_analysis, 
            data.analyses, 
            pil_images, 
            output_path
        )
        
        return FileResponse(
            output_path,
            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
            filename=output_filename
        )

    except Exception as e:
        print(f"Generate Slides Data Error: {e}")
        return JSONResponse(status_code=500, content={"error": f"ç”Ÿæˆå¤±æ•—: {str(e)}"})


@app.post("/api/generate-slides")
async def generate_slides(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    gemini_key: str = Form(None),
    selected_pages: str = Form(None)
):
    """
    [Legacy] æ¥æ”¶ PDF æª”æ¡ˆï¼Œä½¿ç”¨ Gemini Vision åˆ†æä¸¦ç”Ÿæˆ PPTXã€‚
    ä¿ç•™çµ¦èˆŠç‰ˆ UI ä½¿ç”¨ã€‚
    """
    # é©—è­‰è¼¸å…¥
    if not gemini_key:
        return JSONResponse(
            status_code=400, 
            content={"error": "è«‹æä¾› Gemini API Key (BYOK æ¨¡å¼)"}
        )
    
    if not file.filename.lower().endswith(".pdf"):
        return JSONResponse(
            status_code=400,
            content={"error": "è«‹ä¸Šå‚³ PDF æª”æ¡ˆ"}
        )

    try:
        # è®€å– PDF å…§å®¹
        pdf_bytes = await file.read()
        
        # è§£æ selected_pages
        selected_indices = None
        if selected_pages:
            try:
                selected_indices = json.loads(selected_pages)
                if not isinstance(selected_indices, list):
                    selected_indices = None
            except Exception as e:
                print(f"è§£æ selected_pages å¤±æ•—: {e}")
                
        # é€²è¡Œè™•ç†
        pptx_path = await slide_generator.process_pdf_to_slides(
            pdf_bytes=pdf_bytes,
            api_key=gemini_key,
            filename=file.filename,
            selected_indices=selected_indices
        )
        
        # è¨­å®šå›å‚³æª”å
        output_filename = os.path.splitext(file.filename)[0] + ".pptx"
        output_filename = output_filename.encode('utf-8').decode('latin-1') # é¿å… header äº‚ç¢¼

        # è¨­å®šèƒŒæ™¯ä»»å‹™åˆªé™¤æš«å­˜æ“‹
        # æ³¨æ„: FileResponse å®Œæˆå¾Œé€šå¸¸ä¸æœƒè‡ªå‹•åˆªé™¤ï¼Œéœ€è‡ªè¡Œç®¡ç†æˆ–ä½¿ç”¨ tempfile
        # é€™è£¡ç°¡å–®å¯¦ä½œï¼šå»¶é²åˆªé™¤ (ä¸å®Œç¾ä½†å¯ç”¨)
        
        return FileResponse(
            pptx_path,
            media_type="application/vnd.openxmlformats-officedocument.presentationml.presentation",
            filename=output_filename
        )

    except ValueError as ve:
        return JSONResponse(status_code=400, content={"error": str(ve)})
    except Exception as e:
        print(f"Slide Gen Error: {e}")
        return JSONResponse(status_code=500, content={"error": f"ç”Ÿæˆå¤±æ•—: {str(e)}"})


if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run("main:app", host="0.0.0.0", port=port, reload=True)
